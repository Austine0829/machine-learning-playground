{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c5e8d-a5e0-4c02-9bd4-e412635cabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: Define simple data ---\n",
    "# Suppose these are your observed house sizes (in sq. meters)\n",
    "sizes = np.array([50, 75, 100, 125, 150])\n",
    "# And these are the corresponding prices (in thousands)\n",
    "prices = np.array([200, 275, 350, 425, 500])\n",
    "\n",
    "# --- Step 2: Initialize parameters ---\n",
    "w = np.random.randn()  # weight\n",
    "b = np.random.randn()  # bias\n",
    "\n",
    "# --- Step 3: Learning rate and training steps ---\n",
    "learning_rate = 0.00001\n",
    "epochs = 200\n",
    "\n",
    "# Store loss to visualize later\n",
    "loss_history = []\n",
    "\n",
    "# --- Step 4: Training (gradient descent) ---\n",
    "for epoch in range(epochs):\n",
    "    # Prediction\n",
    "    pred = w * sizes + b\n",
    "\n",
    "    print(\"Prediction: \",pred)\n",
    "\n",
    "    # Loss (Mean Squared Error)\n",
    "    loss = np.mean((pred - prices) ** 2)\n",
    "    loss_history.append(loss)\n",
    "\n",
    "    # Gradients (partial derivatives)\n",
    "    dw = np.mean(2 * (pred - prices) * sizes)\n",
    "    db = np.mean(2 * (pred - prices))\n",
    "\n",
    "    # Update parameters using SGD(Stochastic Gradient Descent)\n",
    "    w -= learning_rate * dw\n",
    "    b -= learning_rate * db\n",
    "\n",
    "# --- Step 5: Show results ---\n",
    "print(f\"Trained weight (w): {w:.3f}\")\n",
    "print(f\"Trained bias (b): {b:.3f}\")\n",
    "\n",
    "# --- Step 6: Plot data and learned line ---\n",
    "plt.scatter(sizes, prices, color='blue', label='Actual Data')\n",
    "plt.plot(sizes, w * sizes + b, color='red', label='Learned Line')\n",
    "plt.title(\"Simple House Price Prediction\")\n",
    "plt.xlabel(\"Size (sq. meters)\")\n",
    "plt.ylabel(\"Price (thousands)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Step 7: Predict your own price ---\n",
    "new_size = float(input(\"Enter a house size (sq. meters): \"))\n",
    "predicted_price = w * new_size + b\n",
    "print(f\"Predicted price for {new_size} sq. meters = {predicted_price:.2f} thousand pesos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b568f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulated dataset: house size (in square meters) and price (in thousands)\n",
    "# True relationship: price = 50 * size + 100  (so bias = 100)\n",
    "x = np.array([50, 75, 100, 125, 150, 175, 200])   # house size\n",
    "y = np.array([2550, 3850, 5100, 6400, 7600, 8900, 10100])  # in thousand pesos\n",
    "\n",
    "# Initialize weight (only one parameter)\n",
    "w = 0.0\n",
    "learning_rate = 0.0000001  # small because values are large\n",
    "epochs = 100\n",
    "\n",
    "# For visualization\n",
    "history_w = []\n",
    "history_loss = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Prediction (no bias)\n",
    "    y_pred = w * x\n",
    "\n",
    "    # Mean Squared Error\n",
    "    loss = np.mean((y - y_pred)**2)\n",
    "\n",
    "    # Derivative of loss w.r.t. w\n",
    "    dw = -2 * np.mean(x * (y - y_pred))\n",
    "\n",
    "    # Update rule\n",
    "    w -= learning_rate * dw\n",
    "\n",
    "    history_w.append(w)\n",
    "    history_loss.append(loss)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Epoch {i+1}: w={w:.4f}, loss={loss:.2f}\")\n",
    "\n",
    "# Final results\n",
    "print(f\"\\nFinal weight: {w:.4f}\")\n",
    "print(\"Predictions:\", w * x)\n",
    "\n",
    "# --- Visualization ---\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "# Plot data and predicted line\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(x, y, color='red', label='Actual House Prices')\n",
    "plt.plot(x, w * x, color='blue', label=f'Predicted Line (no bias)')\n",
    "plt.title(\"House Price Prediction with ONE Parameter (No Bias)\")\n",
    "plt.xlabel(\"House Size (sq. meters)\")\n",
    "plt.ylabel(\"Price (thousands)\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_loss, color='green')\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b0b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: Define simple data ---\n",
    "sizes = np.array([50, 75, 100, 125, 150])\n",
    "prices = np.array([200, 275, 350, 425, 500])\n",
    "\n",
    "# --- Helper function for training ---\n",
    "def train_linear_regression(x, y, lr=0.0001, epochs=200):\n",
    "    w = np.random.randn()\n",
    "    b = np.random.randn()\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        pred = w * x + b\n",
    "        loss = np.mean((pred - y) ** 2)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        # Gradients\n",
    "        dw = np.mean(2 * (pred - y) * x)\n",
    "        db = np.mean(2 * (pred - y))\n",
    "\n",
    "        # Update\n",
    "        w -= lr * dw\n",
    "        b -= lr * db\n",
    "\n",
    "    return w, b, loss_history\n",
    "\n",
    "# =========================\n",
    "# 1️⃣ Original Data\n",
    "w_orig, b_orig, loss_orig = train_linear_regression(sizes, prices, lr=0.00001)\n",
    "\n",
    "# Plot original\n",
    "plt.scatter(sizes, prices, color='blue', label='Original Data')\n",
    "plt.plot(sizes, w_orig * sizes + b_orig, color='red', label='Learned Line (Original)')\n",
    "plt.title(\"Original House Price Prediction\")\n",
    "plt.xlabel(\"Size (sq. meters)\")\n",
    "plt.ylabel(\"Price (thousands)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Original Data Trained Parameters:\")\n",
    "print(f\"w = {w_orig:.3f}, b = {b_orig:.3f}\")\n",
    "\n",
    "# =========================\n",
    "# 2️⃣ Normalized Data\n",
    "sizes_norm = (sizes - np.mean(sizes)) / np.std(sizes)\n",
    "prices_norm = (prices - np.mean(prices)) / np.std(prices)\n",
    "\n",
    "w_norm, b_norm, loss_norm = train_linear_regression(sizes_norm, prices_norm, lr=0.01)\n",
    "\n",
    "# Plot normalized\n",
    "plt.scatter(sizes_norm, prices_norm, color='green', label='Normalized Data')\n",
    "plt.plot(sizes_norm, w_norm * sizes_norm + b_norm, color='orange', label='Learned Line (Normalized)')\n",
    "plt.title(\"Normalized House Price Prediction\")\n",
    "plt.xlabel(\"Normalized Size\")\n",
    "plt.ylabel(\"Normalized Price\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Normalized Data Trained Parameters:\")\n",
    "print(f\"w = {w_norm:.3f}, b = {b_norm:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bd2354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: Define simple data ---\n",
    "sizes = np.array([50, 75, 100, 125, 150])\n",
    "prices = np.array([200, 275, 350, 425, 500])\n",
    "\n",
    "# --- Step 1.5: Normalize features and targets ---\n",
    "sizes_norm = (sizes - np.mean(sizes)) / np.std(sizes)\n",
    "prices_norm = (prices - np.mean(prices)) / np.std(prices)\n",
    "\n",
    "# --- Step 2: Initialize parameters ---\n",
    "w = np.random.randn()  # weight\n",
    "b = np.random.randn()  # bias\n",
    "\n",
    "# --- Step 3: Learning rate and training steps ---\n",
    "learning_rate = 0.01  # can use larger LR for normalized data\n",
    "epochs = 200\n",
    "\n",
    "# Store loss to visualize later\n",
    "loss_history = []\n",
    "\n",
    "# --- Step 4: Training (gradient descent) ---\n",
    "for epoch in range(epochs):\n",
    "    # Prediction\n",
    "    pred = w * sizes_norm + b\n",
    "\n",
    "    # Loss (Mean Squared Error)\n",
    "    loss = np.mean((pred - prices_norm) ** 2)\n",
    "    loss_history.append(loss)\n",
    "\n",
    "    # Gradients (partial derivatives)\n",
    "    dw = np.mean(2 * (pred - prices_norm) * sizes_norm)\n",
    "    db = np.mean(2 * (pred - prices_norm))\n",
    "\n",
    "    # Update parameters using SGD\n",
    "    w -= learning_rate * dw\n",
    "    b -= learning_rate * db\n",
    "\n",
    "# --- Step 5: Show results ---\n",
    "print(f\"Trained weight (w): {w:.3f}\")\n",
    "print(f\"Trained bias (b): {b:.3f}\")\n",
    "\n",
    "# --- Step 6: Plot data and learned line ---\n",
    "plt.scatter(sizes_norm, prices_norm, color='blue', label='Normalized Data')\n",
    "plt.plot(sizes_norm, w * sizes_norm + b, color='red', label='Learned Line')\n",
    "plt.title(\"Normalized House Price Prediction\")\n",
    "plt.xlabel(\"Normalized Size\")\n",
    "plt.ylabel(\"Normalized Price\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Step 7: Predict your own price (normalized) ---\n",
    "new_size = float(input(\"Enter a house size (sq. meters): \"))\n",
    "\n",
    "# Normalize the input\n",
    "new_size_norm = (new_size - np.mean(sizes)) / np.std(sizes)\n",
    "\n",
    "# Predict normalized price\n",
    "predicted_price_norm = w * new_size_norm + b\n",
    "\n",
    "# Convert back to original scale\n",
    "predicted_price = predicted_price_norm * np.std(prices) + np.mean(prices)\n",
    "\n",
    "print(f\"Predicted price for {new_size} sq. meters = {predicted_price:.2f} thousand pesos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7132da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: Original data ---\n",
    "sizes = np.array([50, 75, 100, 125, 150])\n",
    "prices = np.array([200, 275, 350, 425, 500])\n",
    "\n",
    "# --- Step 1.5: Normalize ---\n",
    "sizes_norm = (sizes - np.mean(sizes)) / np.std(sizes)\n",
    "prices_norm = (prices - np.mean(prices)) / np.std(prices)\n",
    "\n",
    "# --- Step 2: Simulate \"folds\" for evaluation ---\n",
    "# Let's create 5 simple folds (leave-one-out for example)\n",
    "fold_losses = []\n",
    "\n",
    "for i in range(len(sizes_norm)):\n",
    "    # Split: use i-th point as \"test\", rest as \"train\"\n",
    "    X_train = np.delete(sizes_norm, i)\n",
    "    y_train = np.delete(prices_norm, i)\n",
    "    X_test = sizes_norm[i]\n",
    "    y_test = prices_norm[i]\n",
    "    \n",
    "    # --- Train simple linear regression on this fold ---\n",
    "    w = np.sum((X_train - np.mean(X_train)) * (y_train - np.mean(y_train))) / np.sum((X_train - np.mean(X_train))**2)\n",
    "    b = np.mean(y_train) - w * np.mean(X_train)\n",
    "    \n",
    "    # Predict the test point\n",
    "    y_pred = w * X_test + b\n",
    "    \n",
    "    # Compute loss (squared error)\n",
    "    loss = (y_pred - y_test) ** 2\n",
    "    fold_losses.append(loss)\n",
    "\n",
    "# --- Step 3: Evaluate mean loss ---\n",
    "fold_losses = np.array(fold_losses)\n",
    "mean_loss = np.mean(fold_losses)\n",
    "\n",
    "print(\"Loss per fold:\", fold_losses)\n",
    "print(\"Mean loss across folds:\", mean_loss)\n",
    "\n",
    "# --- Step 4: Optional visualization ---\n",
    "plt.bar(np.arange(1, len(fold_losses)+1), fold_losses, color='skyblue')\n",
    "plt.axhline(mean_loss, color='red', linestyle='--', label=f\"Mean Loss: {mean_loss:.3f}\")\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.ylabel(\"Squared Error\")\n",
    "plt.title(\"Fold Losses and Mean Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd06efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Create sample data ---\n",
    "np.random.seed(42)\n",
    "\n",
    "# Positive correlation\n",
    "x1 = np.arange(0, 10)\n",
    "y1 = x1 + np.random.normal(0, 1, 10)\n",
    "\n",
    "# Negative correlation\n",
    "x2 = np.arange(0, 10)\n",
    "y2 = 10 - x2 + np.random.normal(0, 1, 10)\n",
    "\n",
    "# No correlation\n",
    "x3 = np.arange(0, 10)\n",
    "y3 = np.random.randint(0, 10, 10)\n",
    "\n",
    "# --- Step 2: Plot ---\n",
    "plt.figure(figsize=(13, 4))\n",
    "\n",
    "# Positive correlation\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(x1, y1, color='orange', label='Y values')\n",
    "plt.plot(x1, y1, color='skyblue', linestyle='--', label='X → movement')\n",
    "plt.title(\"Positive Correlation\")\n",
    "plt.xlabel(\"X (increases →)\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "\n",
    "# Negative correlation\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(x2, y2, color='orange', label='Y values')\n",
    "plt.plot(x2, y2, color='skyblue', linestyle='--', label='X → movement')\n",
    "plt.title(\"Negative Correlation\")\n",
    "plt.xlabel(\"X (increases →)\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "\n",
    "# No correlation\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(x3, y3, color='orange', label='Y values')\n",
    "plt.plot(x3, y3, color='skyblue', linestyle='--', label='X → movement')\n",
    "plt.title(\"No Correlation\")\n",
    "plt.xlabel(\"X (increases →)\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Example dataset (arrays only) ---\n",
    "num_rooms = np.array([2, 3, 4, 3, 5, 4, 6])\n",
    "house_size = np.array([1000, 1300, 1600, 1500, 2000, 1800, 2200])\n",
    "distance_to_city = np.array([10, 8, 6, 7, 4, 5, 3])\n",
    "price = np.array([200000, 250000, 300000, 280000, 400000, 350000, 420000])\n",
    "\n",
    "# --- Compute pairwise correlations ---\n",
    "corr_rooms_price = np.corrcoef(num_rooms, price)[0, 1]\n",
    "corr_size_price = np.corrcoef(house_size, price)[0, 1]\n",
    "corr_distance_price = np.corrcoef(distance_to_city, price)[0, 1]\n",
    "corr_rooms_size = np.corrcoef(num_rooms, house_size)[0, 1]\n",
    "\n",
    "print(\"Correlation (num_rooms vs price):\", round(corr_rooms_price, 2))\n",
    "print(\"Correlation (house_size vs price):\", round(corr_size_price, 2))\n",
    "print(\"Correlation (distance_to_city vs price):\", round(corr_distance_price, 2))\n",
    "print(\"Correlation (num_rooms vs house_size):\", round(corr_rooms_size, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e9a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Normal Distribution ---\n",
    "normal_data = np.random.normal(loc=50, scale=10, size=1000)\n",
    "\n",
    "# --- 2. Skewed Distribution (right-skewed) ---\n",
    "skewed_data = np.random.exponential(scale=10, size=1000) + 20\n",
    "\n",
    "# --- 3. Data with Gaps ---\n",
    "gap_data = np.concatenate([\n",
    "    np.random.normal(30, 5, 500),  # cluster 1\n",
    "    np.random.normal(70, 5, 500)   # cluster 2\n",
    "])\n",
    "\n",
    "# --- Plotting ---\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 12))\n",
    "\n",
    "# Normal\n",
    "axes[0].hist(normal_data, bins=30, color='skyblue', edgecolor='black')\n",
    "axes[0].set_title(\"Normal Distribution\")\n",
    "axes[0].set_xlabel(\"Value\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Skewed\n",
    "axes[1].hist(skewed_data, bins=30, color='salmon', edgecolor='black')\n",
    "axes[1].set_title(\"Right-Skewed Distribution\")\n",
    "axes[1].set_xlabel(\"Value\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Gap\n",
    "axes[2].hist(gap_data, bins=30, color='lightgreen', edgecolor='black')\n",
    "axes[2].set_title(\"Data with Gaps (Bimodal)\")\n",
    "axes[2].set_xlabel(\"Value\")\n",
    "axes[2].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Data Generation ---\n",
    "\n",
    "# Normal distribution\n",
    "normal_data = np.random.normal(loc=50, scale=10, size=1000)\n",
    "\n",
    "# Positive skew (tail to the right)\n",
    "pos_skew_data = np.random.exponential(scale=10, size=1000) + 30\n",
    "\n",
    "# Negative skew (tail to the left)\n",
    "neg_skew_data = -np.random.exponential(scale=10, size=1000) + 70\n",
    "\n",
    "# --- Plotting ---\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 12))\n",
    "\n",
    "# Function to plot histogram with mean & median\n",
    "def plot_hist(data, ax, title):\n",
    "    ax.hist(data, bins=30, color='skyblue', edgecolor='black')\n",
    "    mean = np.mean(data)\n",
    "    median = np.median(data)\n",
    "    ax.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')\n",
    "    ax.axvline(median, color='green', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.legend()\n",
    "\n",
    "# Normal\n",
    "plot_hist(normal_data, axes[0], \"Normal Distribution\")\n",
    "\n",
    "# Positive skew\n",
    "plot_hist(pos_skew_data, axes[1], \"Positive Skew (Right Tail)\")\n",
    "\n",
    "# Negative skew\n",
    "plot_hist(neg_skew_data, axes[2], \"Negative Skew (Left Tail)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ea64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate uniform random numbers between 0 and 1\n",
    "data = np.random.uniform(0, 1, 10000)\n",
    "\n",
    "plt.hist(data, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Uniform Distribution (0 to 1)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c1d94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.591\n",
      "Variance: 0.241719\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate Bernoulli samples (1=success, 0=failure)\n",
    "p = 0.6  # probability of success\n",
    "data = np.random.binomial(1, p, 1000)\n",
    "\n",
    "plt.hist(data, bins=2, edgecolor='black')\n",
    "plt.xticks([0, 1])\n",
    "plt.title(f\"Bernoulli Distribution (p={p})\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean:\", np.mean(data))\n",
    "print(\"Variance:\", np.var(data))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
