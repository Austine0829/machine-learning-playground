{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3e67f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 23:12:11.521967: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-06 23:12:13.183617: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-06 23:12:16.477044: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "/home/austine/Desktop/machine-learning-playground/.venv/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "/home/austine/Desktop/machine-learning-playground/.venv/lib/python3.13/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "2026-01-06 23:12:22.740005: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as tfhub\n",
    "import librosa \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "yamnet_model = tfhub.load(\"https://tfhub.dev/google/yamnet/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24563369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting the songs embbeding in folder calm:   0%|          | 0/300 [00:00<?, ?it/s]2026-01-06 23:12:30.725373: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 24379392 exceeds 10% of free system memory.\n",
      "Extracting the songs embbeding in folder calm:   0%|          | 1/300 [00:04<23:33,  4.73s/it]2026-01-06 23:12:31.125688: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 24379392 exceeds 10% of free system memory.\n",
      "Extracting the songs embbeding in folder calm:   1%|          | 2/300 [00:04<10:25,  2.10s/it]2026-01-06 23:12:31.485865: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 24379392 exceeds 10% of free system memory.\n",
      "Extracting the songs embbeding in folder calm:   1%|          | 3/300 [00:05<06:25,  1.30s/it]2026-01-06 23:12:31.697308: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 24379392 exceeds 10% of free system memory.\n",
      "Extracting the songs embbeding in folder calm:   1%|▏         | 4/300 [00:05<04:37,  1.07it/s]2026-01-06 23:12:32.197124: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 24379392 exceeds 10% of free system memory.\n",
      "Extracting the songs embbeding in folder calm:  39%|███▉      | 117/300 [00:36<00:58,  3.13it/s]/tmp/ipykernel_20348/119899614.py:18: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  waveform, _ = librosa.load(file_path, sr=16000, mono=True)\n",
      "/home/austine/Desktop/machine-learning-playground/.venv/lib/python3.13/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Extracting the songs embbeding in folder calm:  39%|███▉      | 118/300 [00:36<01:00,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error has occured in file path ../librosa/vibes/calm/jazz.00054.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting the songs embbeding in folder calm: 100%|██████████| 300/300 [01:20<00:00,  3.73it/s]\n",
      "Extracting the songs embbeding in folder chill: 100%|██████████| 200/200 [00:46<00:00,  4.32it/s]\n",
      "Extracting the songs embbeding in folder chaotic: 100%|██████████| 200/200 [00:43<00:00,  4.57it/s]\n",
      "Extracting the songs embbeding in folder energetic: 100%|██████████| 300/300 [01:07<00:00,  4.46it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../librosa/vibes\"\n",
    "dataset_csv_path = \"songs_embedding.csv\"\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "vibe_map = {\"calm\": 0,\n",
    "            \"chaotic\": 1,\n",
    "            \"chill\": 2,\n",
    "            \"energetic\": 3}\n",
    "\n",
    "if not os.path.exists(dataset_csv_path):\n",
    "    for vibe in os.listdir(dataset_path):\n",
    "        vibe_path = os.path.join(dataset_path, vibe)\n",
    "        for file in tqdm(os.listdir(vibe_path), desc=f\"Extracting the songs embbeding in folder {vibe}\"):\n",
    "            file_path = os.path.join(vibe_path, file)\n",
    "            try:\n",
    "                waveform, _ = librosa.load(file_path, sr=16000, mono=True)\n",
    "                waveform = waveform.astype(np.float32)\n",
    "\n",
    "                _, embeddings, _ = yamnet_model(waveform)\n",
    "                song_embeddings = tf.reduce_mean(embeddings, axis=0)\n",
    "\n",
    "                X.append(song_embeddings.numpy())\n",
    "                y.append(vibe_map[vibe]) \n",
    "\n",
    "            except:\n",
    "                print(f\"Error has occured in file path {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0722aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dataset_csv_path):\n",
    "    df = pd.DataFrame(X)\n",
    "    df[\"label\"] = y\n",
    "\n",
    "    df.to_csv(dataset_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c203741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_csv_path, index_col=0)\n",
    "\n",
    "X = np.array(df.drop(columns=[\"label\"]))\n",
    "y = np.array(df[\"label\"])\n",
    "\n",
    "vibe_label = np.array([\"calm\",\n",
    "                       \"chaotic\",\n",
    "                       \"chill\",\n",
    "                       \"energetic\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1024,)),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(len(vibe_label), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8223f9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7574 - loss: 0.6040 - val_accuracy: 0.8188 - val_loss: 0.8071\n",
      "Epoch 2/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8967 - loss: 0.3127 - val_accuracy: 0.8500 - val_loss: 0.7273\n",
      "Epoch 3/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9186 - loss: 0.2550 - val_accuracy: 0.8687 - val_loss: 0.6577\n",
      "Epoch 4/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9155 - loss: 0.2421 - val_accuracy: 0.8750 - val_loss: 0.6600\n",
      "Epoch 5/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9327 - loss: 0.1799 - val_accuracy: 0.8875 - val_loss: 0.5529\n",
      "Epoch 6/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9468 - loss: 0.1781 - val_accuracy: 0.8938 - val_loss: 0.6080\n",
      "Epoch 7/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9405 - loss: 0.1525 - val_accuracy: 0.8750 - val_loss: 0.5800\n",
      "Epoch 8/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9484 - loss: 0.1377 - val_accuracy: 0.8875 - val_loss: 0.5331\n",
      "Epoch 9/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9546 - loss: 0.1310 - val_accuracy: 0.8813 - val_loss: 0.4891\n",
      "Epoch 10/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9671 - loss: 0.1149 - val_accuracy: 0.8875 - val_loss: 0.4325\n",
      "Epoch 11/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9609 - loss: 0.1154 - val_accuracy: 0.8875 - val_loss: 0.4720\n",
      "Epoch 12/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9765 - loss: 0.0834 - val_accuracy: 0.9000 - val_loss: 0.4069\n",
      "Epoch 13/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9687 - loss: 0.0915 - val_accuracy: 0.9125 - val_loss: 0.3851\n",
      "Epoch 14/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9687 - loss: 0.0801 - val_accuracy: 0.9000 - val_loss: 0.3812\n",
      "Epoch 15/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9718 - loss: 0.0864 - val_accuracy: 0.9000 - val_loss: 0.4221\n",
      "Epoch 16/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9718 - loss: 0.0918 - val_accuracy: 0.8750 - val_loss: 0.3973\n",
      "Epoch 17/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9734 - loss: 0.0710 - val_accuracy: 0.8875 - val_loss: 0.4183\n",
      "Epoch 18/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9859 - loss: 0.0527 - val_accuracy: 0.8938 - val_loss: 0.3570\n",
      "Epoch 19/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9859 - loss: 0.0619 - val_accuracy: 0.9062 - val_loss: 0.4069\n",
      "Epoch 20/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9812 - loss: 0.0566 - val_accuracy: 0.8875 - val_loss: 0.3623\n",
      "Epoch 21/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9812 - loss: 0.0539 - val_accuracy: 0.8813 - val_loss: 0.5208\n",
      "Epoch 22/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9859 - loss: 0.0498 - val_accuracy: 0.8750 - val_loss: 0.5521\n",
      "Epoch 23/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9859 - loss: 0.0566 - val_accuracy: 0.8687 - val_loss: 0.5724\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce3d7450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.90      0.90      0.90        60\n",
      "     chaotic       0.88      0.90      0.89        40\n",
      "       chill       0.89      0.85      0.87        40\n",
      "   energetic       0.85      0.87      0.86        60\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.88      0.88      0.88       200\n",
      "weighted avg       0.88      0.88      0.88       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred_labels,\n",
    "    target_names=vibe_label\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ff3e416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "energetic\n"
     ]
    }
   ],
   "source": [
    "waveform, _ = librosa.load(\"../librosa/energetic.2.mp3\", sr=16000, mono=True)\n",
    "waveform = waveform.astype(np.float32)\n",
    "\n",
    "_, embeddings, _ = yamnet_model(waveform)\n",
    "song_embeddings = tf.reduce_mean(embeddings, axis=0)\n",
    "\n",
    "pred = model.predict(song_embeddings.numpy().reshape(1, -1))\n",
    "predicted_class = tf.argmax(pred, axis=1).numpy()[0]\n",
    "\n",
    "print(vibe_label[predicted_class])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
